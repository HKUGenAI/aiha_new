{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:11:20.577412Z",
     "start_time": "2025-01-14T16:11:20.566243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxiang/miniconda3/envs/layout/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pypdfium2\n",
    "\n",
    "from PIL import Image\n",
    "from surya.detection import batch_text_detection\n",
    "from surya.layout import batch_layout_detection\n",
    "\n",
    "from surya.model.detection.model import load_model as load_det_model, load_processor as load_det_processor\n",
    "from surya.model.layout.model import load_model as load_layout_model\n",
    "from surya.model.layout.processor import load_processor as load_layout_processor\n",
    "from surya.settings import Settings\n",
    "\n",
    "input_file = \"inputs/EngineeringatHKUACenturyofExcellence.pdf\"\n",
    "file_name = \"EngineeringatHKUACenturyofExcellence\"\n",
    "\n",
    "# image = Image.open(IMAGE_PATH)\n",
    "# model = load_layout_model()\n",
    "# processor = load_layout_processor()\n",
    "# det_model = load_det_model()\n",
    "# det_processor = load_det_processor()\n",
    "#\n",
    "# # layout_predictions is a list of dicts, one per image\n",
    "# line_predictions = batch_text_detection([image], det_model, det_processor)\n",
    "# layout_predictions = batch_layout_detection([image], model, processor, line_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:12:13.267454Z",
     "start_time": "2025-01-14T16:12:13.255371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout model datalab-to/surya_layout on device cuda with dtype torch.float16\n",
      "Loaded detection model vikp/surya_det3 on device cuda with dtype torch.float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Settings(TORCH_DEVICE=None, IMAGE_DPI=96, IMAGE_DPI_HIGHRES=192, IN_STREAMLIT=False, ENABLE_EFFICIENT_ATTENTION=True, ENABLE_CUDNN_ATTENTION=False, FLATTEN_PDF=True, DATA_DIR='data', RESULT_DIR='results', BASE_DIR='/home/cxiang/miniconda3/envs/layout/lib/python3.10/site-packages', FONT_DIR='/home/cxiang/miniconda3/envs/layout/lib/python3.10/site-packages/static/fonts', DETECTOR_BATCH_SIZE=None, DETECTOR_MODEL_CHECKPOINT='vikp/surya_det3', DETECTOR_BENCH_DATASET_NAME='vikp/doclaynet_bench', DETECTOR_IMAGE_CHUNK_HEIGHT=1400, DETECTOR_TEXT_THRESHOLD=0.6, DETECTOR_BLANK_THRESHOLD=0.35, DETECTOR_POSTPROCESSING_CPU_WORKERS=8, DETECTOR_MIN_PARALLEL_THRESH=3, COMPILE_DETECTOR=False, RECOGNITION_MODEL_CHECKPOINT='vikp/surya_rec2', RECOGNITION_MAX_TOKENS=175, RECOGNITION_BATCH_SIZE=None, RECOGNITION_IMAGE_SIZE={'height': 256, 'width': 896}, RECOGNITION_RENDER_FONTS={'all': '/home/cxiang/miniconda3/envs/layout/lib/python3.10/site-packages/static/fonts/GoNotoCurrent-Regular.ttf', 'zh': '/home/cxiang/miniconda3/envs/layout/lib/python3.10/site-packages/static/fonts/GoNotoCJKCore.ttf', 'ja': '/home/cxiang/miniconda3/envs/layout/lib/python3.10/site-packages/static/fonts/GoNotoCJKCore.ttf', 'ko': '/home/cxiang/miniconda3/envs/layout/lib/python3.10/site-packages/static/fonts/GoNotoCJKCore.ttf'}, RECOGNITION_FONT_DL_BASE='https://github.com/satbyy/go-noto-universal/releases/download/v7.0', RECOGNITION_BENCH_DATASET_NAME='vikp/rec_bench', RECOGNITION_PAD_VALUE=255, COMPILE_RECOGNITION=False, RECOGNITION_ENCODER_BATCH_DIVISOR=1, LAYOUT_MODEL_CHECKPOINT='datalab-to/surya_layout', LAYOUT_IMAGE_SIZE={'height': 768, 'width': 768}, LAYOUT_SLICE_MIN={'height': 1500, 'width': 1500}, LAYOUT_SLICE_SIZE={'height': 1200, 'width': 1200}, LAYOUT_BATCH_SIZE=None, LAYOUT_BENCH_DATASET_NAME='vikp/publaynet_bench', LAYOUT_MAX_BOXES=100, COMPILE_LAYOUT=False, ORDER_BENCH_DATASET_NAME='vikp/order_bench', TABLE_REC_MODEL_CHECKPOINT='vikp/surya_tablerec', TABLE_REC_IMAGE_SIZE={'height': 640, 'width': 640}, TABLE_REC_MAX_BOXES=512, TABLE_REC_MAX_ROWS=384, TABLE_REC_BATCH_SIZE=None, TABLE_REC_BENCH_DATASET_NAME='vikp/fintabnet_bench', COMPILE_TABLE_REC=False, OCR_ERROR_MODEL_CHECKPOINT='datalab-to/ocr_error_detection', OCR_ERROR_BATCH_SIZE=None, COMPILE_OCR_ERROR=False, TESSDATA_PREFIX=None, COMPILE_ALL=False, TORCH_DEVICE_MODEL='cuda', DETECTOR_STATIC_CACHE=False, RECOGNITION_STATIC_CACHE=False, LAYOUT_STATIC_CACHE=False, TABLE_REC_STATIC_CACHE=False, OCR_ERROR_STATIC_CACHE=False, MODEL_DTYPE=torch.float16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout_model = load_layout_model()\n",
    "layout_processor = load_layout_processor()\n",
    "det_model = load_det_model()\n",
    "det_processor = load_det_processor()\n",
    "\n",
    "\n",
    "settings = Settings()\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T16:11:20.650685Z",
     "start_time": "2025-01-14T16:11:20.590526Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_page_image(pdf_file, dpi=settings.IMAGE_DPI_HIGHRES):\n",
    "    # stream = io.BytesIO(pdf_file.getvalue())\n",
    "    doc = pypdfium2.PdfDocument(pdf_file)\n",
    "    png_images = []\n",
    "    for page in range(len(doc)):\n",
    "        renderer = doc.render(\n",
    "            pypdfium2.PdfBitmap.to_pil,\n",
    "            page_indices=[page],\n",
    "            scale=dpi / 72,\n",
    "        )\n",
    "        png = list(renderer)[0]\n",
    "        png_image = png.convert(\"RGB\")\n",
    "        png_images.append(png_image)\n",
    "    doc.close()\n",
    "    return png_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png_images = get_page_image(input_file)\n",
    "len(png_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing layout: 100%|██████████| 7/7 [00:05<00:00,  1.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LayoutResult(bboxes=[LayoutBox(polygon=[[1308.224609375, 141.5771484375], [1486.9013671875, 141.5771484375], [1486.9013671875, 331.640625], [1308.224609375, 331.640625]], confidence=0.99951171875, label='Picture', position=0, top_k={'Picture': 0.99951171875, 'SectionHeader': 9.47713851928711e-05, 'Text': 8.118152618408203e-05, 'PageHeader': 3.272294998168945e-05, 'Handwriting': 1.8537044525146484e-05}, bbox=[1308.224609375, 141.5771484375, 1486.9013671875, 331.640625]), LayoutBox(polygon=[[195.767578125, 460.83984375], [1477.5791015625, 460.83984375], [1477.5791015625, 837.890625], [195.767578125, 837.890625]], confidence=0.9990234375, label='SectionHeader', position=1, top_k={'SectionHeader': 0.9990234375, 'Picture': 0.0006933212280273438, 'Text': 0.00018799304962158203, 'Handwriting': 7.271766662597656e-06, 'Figure': 3.993511199951172e-06}, bbox=[195.767578125, 460.83984375, 1477.5791015625, 837.890625]), LayoutBox(polygon=[[3.495849609375, 909.375], [1594.107421875, 909.375], [1594.107421875, 2220.9736328125], [3.495849609375, 2220.9736328125]], confidence=0.99658203125, label='Picture', position=2, top_k={'Picture': 0.99658203125, 'Text': 0.000698089599609375, 'SectionHeader': 0.00022292137145996094, 'Figure': 0.00018608570098876953}, bbox=[3.495849609375, 909.375, 1594.107421875, 2220.9736328125])], image_bbox=[0.0, 0.0, 1591.0, 2246.0], sliced=True),\n",
       " LayoutResult(bboxes=[LayoutBox(polygon=[[255.652099609375, 778.125], [1328.3046875, 778.125], [1328.3046875, 1098.046875], [255.652099609375, 1098.046875]], confidence=0.947265625, label='SectionHeader', position=0, top_k={'SectionHeader': 0.947265625, 'Text': 0.038360595703125, 'Picture': 0.0137786865234375, 'PageHeader': 0.00019061565399169922, 'Handwriting': 9.930133819580078e-05}, bbox=[255.652099609375, 778.125, 1328.3046875, 1098.046875]), LayoutBox(polygon=[[85.3466796875, 1237.02880859375], [1528.4814453125, 1237.02880859375], [1528.4814453125, 2168.3671875], [85.3466796875, 2168.3671875]], confidence=0.97802734375, label='Text', position=1, top_k={'Text': 0.97802734375, 'SectionHeader': 0.0075531005859375, 'PageHeader': 0.006954193115234375, 'Picture': 0.00424957275390625, 'TextInlineMath': 0.001079559326171875}, bbox=[85.3466796875, 1237.02880859375, 1528.4814453125, 2168.3671875])], image_bbox=[0.0, 0.0, 1589.0, 2246.0], sliced=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png_images = get_page_image(input_file)\n",
    "# line_predictions = batch_text_detection(png_images, det_model, det_processor)\n",
    "preds = batch_layout_detection(png_images, layout_model, layout_processor)\n",
    "preds[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bboxes - detected bounding boxes for text\n",
    "- bbox - the axis-aligned rectangle for the text line in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner.\n",
    "- polygon - the polygon for the text line in (x1, y1), (x2, y2), (x3, y3), (x4, y4) format. The points are in clockwise order from the top left.\n",
    "- position - the reading order of the box.\n",
    "- label - the label for the bbox. One of Caption, Footnote, Formula, List-item, Page-footer, Page-header, Picture, Figure, Section-header, - - - Table, Form, Table-of-contents, Handwriting, Text, Text-inline-math.\n",
    "- top_k - the top-k other potential labels for the box. A dictionary with labels as keys and confidences as values.\n",
    "- page - the page number in the file\n",
    "- image_bbox - the bbox for the image in (x1, y1, x2, y2) format. (x1, y1) is the top left corner, and (x2, y2) is the bottom right corner. All line bboxes will be contained within this bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "doc_bbs = []\n",
    "doc_images = []\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    image_array = np.array(png_images[i])   \n",
    "    doc_images.append({\n",
    "        \"id\": f\"{file_name}_{i}\",\n",
    "        \"page\": i,\n",
    "        \"image\": image_array,\n",
    "    })\n",
    "\n",
    "    for j, box in enumerate(pred.bboxes):\n",
    "        x1, y1, x2, y2 = map(int, box.bbox)\n",
    "\n",
    "        doc_bbs.append({\n",
    "            \"id\": f\"{file_name}_{i}_{j}\",\n",
    "            \"page\": i,\n",
    "            \"xyxy\": box.bbox,\n",
    "            \"image_array\": image_array[y1:y2, x1:x2],\n",
    "            \"type_str\": box.label,\n",
    "            \"type_conf\": box.confidence,\n",
    "        })\n",
    "\n",
    "df_bbs = pd.DataFrame(doc_bbs)\n",
    "df_bbs.to_pickle(f\"results/{file_name}_bbs.pkl\")\n",
    "\n",
    "df_images = pd.DataFrame(doc_images)\n",
    "df_images.to_pickle(f\"results/{file_name}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
